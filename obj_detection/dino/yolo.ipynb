{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "repo_dir = os.getcwd().split('dslab25')[0] + 'dslab25/'\n",
    "dino_dir = os.path.join(repo_dir, \"obj_detection/dino/\")\n",
    "images = os.path.join(repo_dir, \"training/vacuum_pump/images/augmented/\")\n",
    "labels = os.path.join(repo_dir, \"training/vacuum_pump/annotation/augmented/\")\n",
    "\n",
    "yolo_train_images = os.path.join(repo_dir, \"yolo_dataset/images/train\")\n",
    "yolo_val_images = os.path.join(repo_dir, \"yolo_dataset/images/val\")\n",
    "yolo_train_labels = os.path.join(repo_dir, \"yolo_dataset/labels/train\")\n",
    "yolo_val_labels = os.path.join(repo_dir, \"yolo_dataset/labels/val\")\n",
    "yaml_path = os.path.join(repo_dir, \"yolo_dataset/yolo_dataset.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv12 model (you can use \"yolov12n.pt\", \"yolov12s.pt\", \"yolov12m.pt\" etc.)\n",
    "model_path = \"yolo12m.pt\"  # pretrained weights from Ultralytics\n",
    "\n",
    "TRAINING_EVAL_SPLIT = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the yolo dataset folder (just copying files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folders\n",
    "os.makedirs(yolo_train_images, exist_ok=True)\n",
    "os.makedirs(yolo_val_images, exist_ok=True)\n",
    "os.makedirs(yolo_train_labels, exist_ok=True)\n",
    "os.makedirs(yolo_val_labels, exist_ok=True)\n",
    "\n",
    "# This function copies one image and its label\n",
    "def copy_image_label(task):\n",
    "\tsrc_image, dst_image, src_label, dst_label = task\n",
    "\tif os.path.exists(src_image) and os.path.exists(src_label):\n",
    "\t\tshutil.copy(src_image, dst_image)\n",
    "\t\tshutil.copy(src_label, dst_label)\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for folder in os.listdir(images):\n",
    "\tfolder_path = os.path.join(images, folder)\n",
    "\tif not os.path.isdir(folder_path):\n",
    "\t\tcontinue  # skip if not a folder\n",
    "\n",
    "\timage_files = os.listdir(folder_path)\n",
    "\trandom.shuffle(image_files)\n",
    "\n",
    "\t# Split into 90% train, 10% validation\n",
    "\tsplit_idx = int(len(image_files) * TRAINING_EVAL_SPLIT)\n",
    "\ttrain_images = image_files[:split_idx]\n",
    "\tval_images = image_files[split_idx:]\n",
    "\n",
    "\tprint(len(train_images))\n",
    "\n",
    "\tfor image in train_images:\n",
    "\t\tsrc_image = os.path.join(images, folder, image)\n",
    "\t\tdst_image = os.path.join(yolo_train_images, image)\n",
    "\t\tsrc_label = os.path.join(labels, folder, image.replace(\".jpg\", \".txt\"))\n",
    "\t\tdst_label = os.path.join(yolo_train_labels, image.replace(\".jpg\", \".txt\"))\n",
    "\t\ttasks.append((src_image, dst_image, src_label, dst_label))\n",
    "\n",
    "\tfor image in val_images:\n",
    "\t\tsrc_image = os.path.join(images, folder, image)\n",
    "\t\tdst_image = os.path.join(yolo_val_images, image)\n",
    "\t\tsrc_label = os.path.join(labels, folder, image.replace(\".jpg\", \".txt\"))\n",
    "\t\tdst_label = os.path.join(yolo_val_labels, image.replace(\".jpg\", \".txt\"))\n",
    "\t\ttasks.append((src_image, dst_image, src_label, dst_label))\n",
    "\n",
    "# Parallel copy using threads\n",
    "with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "\tlist(executor.map(copy_image_label, tasks))\n",
    "\n",
    "# Create dataset YAML\n",
    "dataset_yaml = {\n",
    "\t\"path\": os.path.join(repo_dir, \"yolo_dataset\"),\n",
    "\t\"train\": \"images/train\",\n",
    "\t\"val\": \"images/val\",\n",
    "\t\"nc\": 8,  # Number of classes, set to 1 if you only care about bounding boxes\n",
    "\t\"names\": [\"stage_0\", \"stage_1\", \"stage_2\", \"stage_3\", \"stage_4\", \"stage_5\", \"stage_6\", \"stage_7\"]  # name of your single class\n",
    "}\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "\tyaml.dump(dataset_yaml, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and train model\n",
    "model = YOLO(model_path)  # Load YOLOv12 model (Ultralytics must support it)\n",
    "\n",
    "model.train(\n",
    "\tdata=yaml_path,\n",
    "\tepochs=1,\n",
    "\timgsz=640,\n",
    "\tbatch=32,\n",
    "\tname=\"yolov12_boundingbox\",\n",
    "\tproject=os.path.join(dino_dir, \"yolo_runs\"),\n",
    "\tdevice=0 if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on real video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "video_path = os.path.join(repo_dir, \"assets/vacuum_pump/videos/01_run1_cam_2_1024x1024_15fps_3mbps.mp4\")\n",
    "video_labels_path = os.path.join(repo_dir, \"assets/vacuum_pump/videos/output.txt\")\n",
    "# Path to your trained YOLOv12 weights (adjust as needed)\n",
    "yolo_model_path = os.path.join(repo_dir, \"obj_detection/dino/yolo_runs/yolov12_boundingbox11\", \"weights\", \"best.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth labels.\n",
    "print(f\"Loading labels from: {video_labels_path}\")\n",
    "\n",
    "frame_to_class = {}\n",
    "with open(video_labels_path, 'r') as f:\n",
    "\tfor line in f:\n",
    "\t\tparts = line.strip().split()\n",
    "\t\tif len(parts) == 3:\n",
    "\t\t\tstate_class, start_frame, end_frame = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "\t\t\tfor frame_idx in range(start_frame, end_frame + 1):\n",
    "\t\t\t\tframe_to_class[frame_idx] = state_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video.\n",
    "print(f\"Loading video from: {video_path}\")\n",
    "video = cv2.VideoCapture(video_path)\n",
    "if not video.isOpened():\n",
    "\tprint(\"Error: Could not open video file.\")\n",
    "\treturn\n",
    "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Video info: {total_frames} frames, {fps} fps\")\n",
    "\n",
    "# Load the YOLO model.\n",
    "print(\"Loading YOLO model...\")\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "print(\"\\n--- Starting YOLO Evaluation ---\")\n",
    "frame_idx = 0\n",
    "frames_to_process = []\n",
    "# Process every 5th frame that has a ground truth label.\n",
    "while True:\n",
    "\tret, frame = video.read()\n",
    "\tif not ret:\n",
    "\t\tbreak\n",
    "\tif frame_idx % 5 == 0 and frame_idx in frame_to_class:\n",
    "\t\tframes_to_process.append((frame_idx, frame))\n",
    "\tframe_idx += 1\n",
    "video.release()\n",
    "print(f\"Total frames to evaluate: {len(frames_to_process)}\")\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for frame_idx, frame in frames_to_process:\n",
    "\ttrue_label = frame_to_class[frame_idx]\n",
    "\t\n",
    "\t# Run YOLO detection on the frame.\n",
    "\tyolo_results = yolo_model(frame)\n",
    "\tif len(yolo_results) == 0 or len(yolo_results[0].boxes) == 0:\n",
    "\t\tprint(f\"Frame {frame_idx}: No detection found. Skipping frame.\")\n",
    "\t\tcontinue\n",
    "\t\n",
    "\t# Retrieve detections and select the one with the highest confidence.\n",
    "\tboxes = yolo_results[0].boxes.data  # Each row: [x1, y1, x2, y2, conf, cls]\n",
    "\tidx = torch.argmax(boxes[:, 4])\n",
    "\tbox = boxes[idx]\n",
    "\t\n",
    "\t# YOLO prediction: class is at index 5.\n",
    "\tpredicted_label = int(box[5].item())\n",
    "\t\n",
    "\tis_correct = predicted_label == true_label\n",
    "\tif is_correct:\n",
    "\t\tcorrect_predictions += 1\n",
    "\ttotal_predictions += 1\n",
    "\t\n",
    "\tprint(f\"Frame {frame_idx}:\")\n",
    "\tprint(f\"  True label: {true_label}\")\n",
    "\tprint(f\"  YOLO Predicted: {predicted_label}\")\n",
    "\tprint(f\"  Correct: {'Yes' if is_correct else 'No'}\")\n",
    "\tprint(\"-\" * 20)\n",
    "\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "print(\"\\nEvaluation Summary:\")\n",
    "print(f\"  Total frames evaluated: {total_predictions}\")\n",
    "print(f\"  Correct predictions: {correct_predictions}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f} ({correct_predictions}/{total_predictions})\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
